---
title: "Bayesian analysis of Neuroimaging data with R"
author: "Chris Hammill<br>Jason Lerch"
date: "2018-06-14"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
#opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```


# Outline

1. Quick overview of algorithms and datasets used today
1. Anatomy and hierarchies
1. Massively univariate classical statistics
1. Meet Reverend Thomas
1. A simple model
1. Diagnostics
1. A more complex example (if we have time)
1. ... 
1. Profit?

---

# The dataset

Describe the example we will be working with

---

# MAGeT - the algorithm

![MAGeT figure](MAGeT-fig.png)

Chakravarty MM, Steadman P, van Eede MC, Calcott RD, Gu V, Shaw P, Raznahan A, Collins DL, Lerch JP. Performing label-fusion-based segmentation using multiple automatically generated templates. Hum Brain Mapp. 2013 Oct;34(10):2635â€“54.

---

# MAGeT - the atlas

Describe atlas here

---

# Load the data

Read in the processed files

```{r}
suppressMessages(library(tidyverse))
adni <- read.csv("ADNI2_BL_MAGeT_Hippocampus_subfields.csv")
names(adni)
```


---
#Reorganize the diagnosis label

```{r}
library(forcats)
adni <- adni %>% 
  mutate(DX_bl=fct_relevel(DX_bl, 
                           "CN", "SMC", "EMCI", "LMCI", "AD"))
```

---

# Data organization

Make the dataframe long rather than wide

```{r}
adniLong <- adni %>% 
  select(-X) %>% 
    gather(structure, volume, L_CA1:R_Mam)
adniLong %>% 
  select(PTID, DX_bl, structure, volume) %>% sample_n(5)
```


---

# A quick look at the data

```{r, fig.height=6}
library(ggplot2)
ggplot(adniLong) + aes(x=DX_bl, y=AGE) + geom_boxplot()
```

---

# A quick look at hippocampal volume

```{r, tidy=FALSE, fig.height=5}
adniLong %>% group_by(PTID) %>% 
  summarize(DX=DX_bl[1], GENDER=PTGENDER[1], HPC=sum(volume)) %>%
  ggplot() + aes(DX, HPC, colour=GENDER) + geom_boxplot()
```

---

# Classic Statistics

1. Decide on model
1. Apply model to every ROI/voxel separately
1. Widen confidence intervals to account for multiple comparisons

---

# map for looping over structures

```{r}
library(broom)
adniLong %>%
  split(.$structure) %>%
  map(~lm(volume ~ AGE+PTGENDER+DX_bl, .)) %>%
  map_dfr(tidy, .id='roi') %>% head(14)
```

---

# better overview

```{r}
rTable <- adniLong %>%
  split(.$structure) %>%
  map(~lm(volume ~ AGE+PTGENDER+DX_bl, .)) %>%
  map_dfr(tidy, .id='roi') %>% 
  filter(startsWith(term, "DX")) %>%
  select(roi, term, statistic) %>%
  spread(term, statistic) 
```

---
# better overview
```{r}
rTable
```

---
# better overview
```{r}
DT::datatable(rTable %>% remove_rownames() %>% 
  column_to_rownames("roi") %>% round(2), options=list(pageLength=7))
```

---

# multiple comparisons - omnibus FDR

```{r}
pTable <- adniLong %>%
  split(.$structure) %>%
  map(~lm(volume ~ AGE+PTGENDER+DX_bl, .)) %>%
  map_dfr(tidy, .id='roi') %>% 
  filter(startsWith(term, "DX")) %>%
  select(roi, term, p.value) %>%
  spread(term, p.value) %>%
  remove_rownames() %>%
  column_to_rownames("roi") %>%
  as.matrix()
qTable <- pTable
qTable[,] <- p.adjust(pTable, 'fdr')
```

---

# multiple comparisons - omnibus FDR

```{r}
qTable
```

---

# Hippocampal anatomical hierarchy

Setting up a simple hierarchy, dividing the hippocampus in grey matter and tracts.

1. Hippocampal Formation
    1. Grey Matter
        1. CA1
        1. CA2/CA3
        1. CA4/DG
        1. subiculum
        1. stratum
        1. Mammilary bodies
    1. White Matter
        1. Alveus
        1. Fimbria
        1. Fornix

---

# Hippocampal anatomical hierarchy

```{r}
library(data.tree)
hpc <- Node$new("HPC")
gm <- hpc$AddChild("GM")
ca1 <- gm$AddChild("CA1")
lca1 <- ca1$AddChild("left CA1")
lca1$volumes <- adni$L_CA1
rca1 <- ca1$AddChild("right CA1")
rca1$volumes <- adni$R_CA1
ca23 <- gm$AddChild("CA2CA3")
lca23 <- ca23$AddChild("left CA2CA3")
lca23$volumes <- adni$L_CA2CA3
rca23 <- ca23$AddChild("right CA2CA3")
rca23$volumes <- adni$R_CA2CA3
ca4 <- gm$AddChild("CA4DG")
lca4 <- ca4$AddChild("left CA4DG")
lca4$volumes <- adni$L_CA4DG
rca4 <- ca4$AddChild("right CA4DG")
rca4$volumes <- adni$R_CA4DG
subiculum <- gm$AddChild("subiculum")
lsubiculum <- subiculum$AddChild("left subiculum")
lsubiculum$volumes <- adni$L_subiculum
rsubiculum <- subiculum$AddChild("right subiculum")
rsubiculum$volumes <- adni$R_subiculum
stratum <- gm$AddChild("stratum")
lstratum <- stratum$AddChild("left stratum")
lstratum$volumes <- adni$L_stratum
rstratum <- stratum$AddChild("right stratum")
rstratum$volumes <- adni$R_stratum
mam <- gm$AddChild("Mammillary bodies")
lmam <- mam$AddChild("left Mammillary bodies")
lmam$volumes <- adni$L_Mam
rmam <- mam$AddChild("right Mammillary bodies")
rmam$volumes <- adni$R_Mam
wm <- hpc$AddChild("WM")
alveus <- wm$AddChild("Alveus")
lalveus <- alveus$AddChild("left Alveus")
lalveus$volumes <- adni$L_Alv
ralveus <- alveus$AddChild("right Alveus")
ralveus$volumes <- adni$R_Alv
fimbria <- wm$AddChild("Fimbria")
lfimbria <- fimbria$AddChild("left Fimbria")
lfimbria$volumes <- adni$L_Fimb
rfimbria <- fimbria$AddChild("right Fimbria")
rfimbria$volumes <- adni$R_Fimb
fornix <- wm$AddChild("Fornix")
lfornix <- fornix$AddChild("left Fornix")
lfornix$volumes <- adni$L_Fornix
rfornix <- fornix$AddChild("right Fornix")
rfornix$volumes <- adni$R_Fornix
```

---

# Hippocampal anatomical hierarchy

```{r}
hpc
```

---

# Hippocampal anatomical hierarchy

```{r, fig.height=6}
SetGraphStyle(hpc, rankdir="LR")
plot(hpc)
```

---
# Aggregate up the tree

```{r}
hpc$Do(function(x){
  x$volumes <- Aggregate(x, "volumes", rowSums)
}, traversal="post-order", filterFun=isNotLeaf)

hpc$Do(function(x) {
  x$meanVolume <- mean(x$volumes)
})
```


---

# Tree graph

```{r, fig.height=4}
library(treemap)
ToDataFrameTable(hpc, "pathString", "meanVolume", "name") %>% 
  mutate(path=strsplit(pathString, "/"), 
         struct=map_chr(path, ~ .x[3]), 
         tissue=map_chr(path, ~ .x[2])) %>% 
  select(struct, tissue, name, meanVolume) %>% 
  treemap(index=c("tissue", "struct"), vSize="meanVolume")
```


---
# Statistics on the tree

```{r}
hpc$Do(function(x){
  adni$volumes <- x$volumes
  x$stats <- 
    lm(volumes ~ AGE+PTGENDER+DX_bl, adni) %>%
    tidy() %>%
    filter(startsWith(term, "DX")) %>%
    select(term, estimate, statistic, p.value)
})
```
---

# Statistics on the tree

```{r}
print(hpc, AD=function(x) 
  x$stats %>% filter(term=="DX_blAD") %>% select(statistic) )
```

---

# Why Bayesian Statistics?

Have you ever...

1. Been confused about what a p-value means?
1. Been frustrated that a difference in significance doesn't mean a significant difference?
1. Known some values for a parameter are impossible but been unable to use that to your advantage?
1. Wanted to ask more interesting questions than whether or not a parameter is or isn't zero?

---

# Why Bayesian Statistics?

Have you ever...

1. Been confused about what a p-value means?
1. Been frustrated that a difference in significance doesn't mean a significant difference?
1. Known some values for a parameter are impossible but been unable to use that to your advantage?
1. Wanted to ask more interesting questions than whether or not a parameter is or isn't zero?

Then Bayesian statistics might be right for you

---

## How you ask?

1. De-emphasis on binary descision. Bayesians avoid null hypothesis tests, instead focusing on
estimating their parameters of interest, and reporting their uncertainty.
1. Bayesian analyses produce a distribution of possible parameter values (the posterior), that
can be used to ask many interesting questions about values. E.g. what is the probability the
effect in the hippocampus is larger than the effect in the anterior cingulate cortex.
1. Bayesian analyses can use prior information. Bayesian analysis requires an *a priori* assessment
of how likely certain parameters are. This can be vague (uninformative) or can precise (informative)
and steer your analysis away from nonsensical results.

---

class: center
# Meet The Reverend

Reverend Thomas Bayes


![](Thomas_Bayes.gif)


---
class: middle

## Bayes' Theorem

- Bayes noticed this useful property for the probabilities for two events "A" and "B"

$$ \color{red}{P(A | B)} = \frac{{\color{blue}{P(B | A)}\color{orange}{P(A)}}}{\color{magenta}{P(B)}} $$
- $\color{red}{P(A|B)}$: The probability of A given that B happened
- $\color{blue}{P(B|A)}$: The probability of B given that A happened
- $\color{orange}{P(A)}$: The probability of A
- $\color{magenta}{P(B)}$: the probability of B

- Bayes did this in the context of the binomial distribution

---
class: middle
# But Who's that behind him!

---
class: center

# It's Pierre-Simon Laplace

![](Pierre-Simon-Laplace.jpg)

---

## Bayesian Statistics

- Laplace generalized Bayes Theorem into it's modern form. While working on sex-ratios in French births.
- Start with some parameters $\theta$
- Collect some data $D$
- And deduce the probability of your parameters 

---

class: middle

# Bayes' Theorem Redux

$$ \color{red}{P(\theta | D)} = \frac{{\color{blue}{P(D | \theta)}\color{orange}{P(\theta)}}}{\color{magenta}{\int P(D | \theta)P(\theta)d\theta}} $$

**Posterior**: $\color{red}{P(\theta|D)}$: 

the probability of our parameters given our data

**Likelihood**: $\color{blue}{P(D|\theta)}$

The probability of our data given our parameters

**Prior**: $\color{orange}{P(\theta)}$

The probability of our parameters before we saw the data 

**Normalizing Constant**: $\color{magenta}{\int P(D | \theta)P(\theta)d\theta}$

The probability of the data averaged over all possible parameter sets


---

class: middle

# Bayes' Theorem Redux

$$ \color{red}{P(\theta | D)} \propto \color{blue}{P(D | \theta)}\color{orange}{P(\theta)}$$

**Posterior**: $\color{red}{P(\theta|D)}$: 

the probability of our parameters given our data

**Likelihood**: $\color{blue}{P(D|\theta)}$

The probability of our data given our parameters

**Prior**: $\color{orange}{P(\theta)}$

The probability of our parameters before we saw the data 

---

class: middle

# Bayes' Theorem Redux

$$ \color{red}{P(\theta | D)} \propto \color{orange}{P(\theta)}\color{blue}{P(D | \theta)}$$

**Posterior**: $\color{red}{P(\theta|D)}$: 

the probability of our parameters given our data

**Prior**: $\color{orange}{P(\theta)}$

The probability of our parameters before we saw the data 

**Likelihood**: $\color{blue}{P(D|\theta)}$

The probability of our data given our parameters

**Pardon the re-ordering**

---
class: middle

# Posterior

$\color{red}{P(\theta|D)}$

- The goal of bayesian statistics
- The posterior is probability distribution over parameters.
- Depends on the data we observed.
- Can be used to answer interesting questions. For
example how likely is an effect between two biologically meaninful boundaries.

---
class: middle

# Prior

$\color{orange}{P(\theta)}$

- This is what we knew before the experiment. 
- The prior is also a probability distribution over parameters.
- Doesn't depend on the data we saw.
- Gives a probability for any value the parameters could take.

---
class: middle

# Likelihood

$\color{blue}{P(D | \theta)}$

- This is how probable our data is given a hypothetical parameter set
- The likelihood is a probability distribution over data (not parameters)
- Is still a function of parameters.

---

# In words

The <font color="red">probability of parameters given our data</font> is proportional to <font color="orange">how probable we
thought they were before</font> adjusted by <font color="blue">how well they agree with the data we saw</font>.

![](posterior.gif)

---

# Many Slides of interest

---

# Installing RMINC

- RMINC provides many convenience functions for working with hierarchically structured volume data. 
- The lead developers are responsive on github and willing to offer help if needed.
- Full install guide can be found at https://github.com/Mouse-Imaging-Centre/RMINC/blob/master/INSTALL

---

#Linux install:

1. Get the minc-toolkit-v2 (https://bic-mni.github.io/)
1. Source the configure script `source /opt/minc/1.9.16/minc-toolkit-config.sh` or where-ever your minc-toolkit version was installed
1. Set your `MINC_PATH` environment variable `export MINC_PATH=/opt/minc/1.9.16/`
1. Open an R session
1. Install `devtools` if you have not already `install.packages("devtools")`
1. Install `RMINC` with 
```{r, eval = FALSE}
devtools::install_github("Mouse-Imaging-Centre/RMINC", 
  dependencies = c("Depends", "Imports", "LinkingTo",
                   "Suggests","Enhances"))

#Mac Install

Mac install is very similar, however fortran libraries are necessary, and so you will likely need the
package manager [brew](https://brew.sh/). From there you will need to run `brew install gcc`

Then find a directory that looks like:

```{r, engine = "bash", eval = FALSE}
/usr/local/Cellar/gcc/7.*.*/lib/gcc/7
```

this needs to be added to your R build variables (makevars)

```{r, eval = FALSE, engine = "bash"}
mkdir $HOME/.R/ ## Ignore error here
touch $HOME/.R/Makevars
echo 'FLIBS=-L/usr/local/Cellar/gcc/7.1.0/lib/gcc/7' >> \
  $HOME/.R/Makevars
```

If this succeeds, go ahead and follow the linux instructions.

